# AI赋能需求开发与管理课程 - 训练营演练设计优化方案（V6.0）

## 📋 方案概述

本方案基于124分评分体系，详细说明各演练的评分标准、操作指南和实施建议，确保演练的可操作性和评分的公平性。

---

## 🎯 评分体系总览

### 总分构成（124分）

```yaml
演练成果分: 53分
  - A1 提示词演练: 5分
  - B0 项目视图演练: 8分
  - B1 流程梳理演练: 8分
  - B2 需求文档演练: 8分
  - B3 用例建模演练: 8分
  - B4 故事拆解演练: 8分
  - B5 质量管理演练: 8分

课堂表现分: 51分
  - 开场展示: 3分
  - 阶段总结: 9分（3次×3分）
  - 出勤准时: 24分（8次×3分）
  - 积极回答: 10分（按次累计，1分/次）
  - 创新分享: 5分（按次累计，1分/次）

综合演练分: 20分
  - C1 综合演练: 20分

保底分设计:
  - 演练成果保底: 约27分（51%）
  - 课堂表现保底: 约16.5分（32%）
  - 综合演练保底: 12分（60%）
  - 总保底: 约57分（46%）
```

---

## 📝 演练成果评分详细标准

### A1：AI工具与提示词演练（5分，30分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **提示词设计质量** | 2.5分 | 1.5分 | |
| - 结构化设计 | 0.5分 | 0.3分 | 是否使用角色、任务、步骤、输出格式等结构 |
| - 角色设定 | 0.5分 | 0.3分 | 角色定义是否清晰、专业 |
| - 上下文管理 | 0.5分 | 0.3分 | 是否提供充分的背景信息和约束条件 |
| - 输出控制 | 0.5分 | 0.3分 | 是否明确输出格式、长度、风格 |
| - 创新性 | 0.5分 | 0.3分 | 是否有独特的提示词技巧或模式 |
| **MCP服务应用** | 2.5分 | 1.5分 | |
| - 配置正确 | 0.5分 | 0.3分 | MCP服务配置是否正确无误 |
| - 调用成功 | 0.5分 | 0.3分 | 能否成功调用MCP服务功能 |
| - 效果明显 | 0.5分 | 0.3分 | MCP服务是否明显提升工作效率 |
| - 实用性 | 0.5分 | 0.3分 | 所选MCP服务是否符合实际需求 |
| - 创新应用 | 0.5分 | 0.3分 | 是否有创新的MCP服务组合或用法 |
| **合计** | **5分** | **3分** | **保底比例：60%** |

#### 演练任务

**任务说明**
- 各组展示自己配置的AI工具箱（GitHub Copilot、Claude等）
- 演示至少2个提示词工程技巧
- 演示至少1个MCP服务的实际应用

**提交成果**
- 提示词设计文档（结构化提示词至少2个）
- MCP服务配置截图和使用演示
- 效果对比说明（使用AI前后的对比）

**评分要点**
- 提示词是否结构清晰、效果显著
- MCP服务是否配置正确、应用合理
- 是否有创新的应用方法
- 演示是否流畅、清晰

---

### B0：项目视图与范围文档演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **Context Diagram完整性** | 3分 | 1.5分 | |
| - 系统边界清晰 | 0.8分 | 0.4分 | 目标系统边界是否明确界定 |
| - 外部实体完整 | 0.8分 | 0.4分 | 是否识别所有相关外部系统和角色 |
| - 数据流准确 | 0.7分 | 0.4分 | 数据流方向和内容是否准确 |
| - 接口定义明确 | 0.7分 | 0.3分 | 系统接口是否清晰定义 |
| **范围文档规范性** | 3分 | 1.5分 | |
| - 目标清晰 | 0.8分 | 0.4分 | 项目目标是否明确、可衡量 |
| - 边界明确 | 0.8分 | 0.4分 | 包含/不包含的内容是否清晰 |
| - 约束合理 | 0.7分 | 0.4分 | 技术、资源、时间约束是否合理 |
| - 假设完整 | 0.7分 | 0.3分 | 关键假设是否识别并记录 |
| **创新与深度** | 2分 | 1分 | |
| - 视角新颖 | 0.7分 | 0.4分 | 是否有独特的分析视角 |
| - 分析深入 | 0.7分 | 0.3分 | 是否深入分析系统边界和接口 |
| - 表达清晰 | 0.6分 | 0.3分 | 图表和文档是否易于理解 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某企业客户关系管理系统（CRM）

**任务说明**
- 使用AI绘制Context Diagram（系统上下文图）
- 编写项目范围说明文档
- 识别系统边界和外部接口

**提交成果**
- Context Diagram（PNG/PlantUML格式）
- 项目范围文档（包含目标、边界、约束、假设）
- AI工具使用说明（如何使用AI完成任务）

**评分要点**
- Context Diagram是否符合UML规范
- 范围文档是否结构完整、内容准确
- 是否有深入的边界分析
- AI工具应用是否有效

---

### B1：业务流程梳理与优化演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **流程图完整性** | 3分 | 1.5分 | |
| - 角色识别 | 0.8分 | 0.4分 | 是否识别所有相关角色和泳道 |
| - 活动完整 | 0.8分 | 0.4分 | 关键活动是否完整覆盖 |
| - 判断合理 | 0.7分 | 0.4分 | 判断节点是否合理设置 |
| - 流转逻辑 | 0.7分 | 0.3分 | 流程流转逻辑是否清晰正确 |
| **AI优化建议** | 3分 | 1.5分 | |
| - 痛点识别 | 1分 | 0.5分 | 是否准确识别流程痛点 |
| - 优化方案 | 1分 | 0.5分 | 优化方案是否可行、创新 |
| - 价值评估 | 1分 | 0.5分 | 优化价值是否量化评估 |
| **创新与深度** | 2分 | 1分 | |
| - 分析深度 | 1分 | 0.5分 | 流程分析是否深入细致 |
| - 优化创新 | 1分 | 0.5分 | 优化建议是否有创新性 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某电商平台订单处理流程

**任务说明**
- 使用AI绘制当前订单处理流程图（泳道图）
- 识别流程中的痛点和瓶颈
- 提出AI赋能的优化建议

**提交成果**
- 当前流程图（BPMN或泳道图）
- 痛点分析文档
- AI优化方案（包含优化后流程图）

**评分要点**
- 流程图是否规范、完整
- 痛点识别是否准确、深入
- 优化方案是否可行、创新
- 价值评估是否量化、合理

---

### B2：需求文档PRD生成演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **PRD结构规范性** | 3分 | 1.5分 | |
| - 模板完整 | 1分 | 0.5分 | 是否包含PRD必备章节 |
| - 层次清晰 | 1分 | 0.5分 | 章节结构是否层次分明 |
| - 格式规范 | 1分 | 0.5分 | 格式是否符合规范标准 |
| **需求描述质量** | 3分 | 1.5分 | |
| - 描述准确 | 1分 | 0.5分 | 需求描述是否准确无歧义 |
| - 逻辑清晰 | 1分 | 0.5分 | 需求逻辑是否清晰连贯 |
| - 可实现性 | 1分 | 0.5分 | 需求是否具备可实现性 |
| **创新与深度** | 2分 | 1分 | |
| - 细节丰富 | 1分 | 0.5分 | 需求细节是否充分描述 |
| - 考虑周全 | 1分 | 0.5分 | 是否考虑边界条件和异常情况 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某在线教育平台"直播课堂"功能

**任务说明**
- 使用AI生成PRD文档
- 包含功能需求、非功能需求、界面设计等
- 确保文档结构完整、描述清晰

**提交成果**
- PRD文档（Markdown格式）
- 功能列表清单
- AI生成过程说明

**评分要点**
- PRD结构是否完整规范
- 需求描述是否准确、详细
- 是否考虑用户体验和边界情况
- AI工具使用是否高效

---

### B3：用例图与规约建模演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **用例图规范性** | 3分 | 1.5分 | |
| - UML标准 | 1分 | 0.5分 | 是否符合UML用例图标准 |
| - 关系准确 | 1分 | 0.5分 | 包含、扩展、泛化关系是否准确 |
| - 边界清晰 | 1分 | 0.5分 | 系统边界和参与者是否清晰 |
| **用例规约详细性** | 3分 | 1.5分 | |
| - 前后置条件 | 1分 | 0.5分 | 前置和后置条件是否明确 |
| - 主流程完整 | 1分 | 0.5分 | 主成功场景是否完整描述 |
| - 异常流处理 | 1分 | 0.5分 | 异常流和备选流是否考虑 |
| **创新与深度** | 2分 | 1分 | |
| - 场景覆盖 | 1分 | 0.5分 | 用例场景覆盖是否全面 |
| - 细节描述 | 1分 | 0.5分 | 用例规约是否细节充分 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某图书管理系统

**任务说明**
- 使用AI绘制用例图
- 编写至少2个核心用例的规约
- 标识用例之间的关系（包含、扩展、泛化）

**提交成果**
- 用例图（PlantUML或图片格式）
- 用例规约文档（至少2个核心用例）
- UML关系说明

**评分要点**
- 用例图是否符合UML规范
- 用例规约是否详细、完整
- 是否考虑异常流和备选流
- 用例粒度是否合理

---

### B4：用户故事拆解与优先级演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **故事拆解合理性** | 3分 | 1.5分 | |
| - 颗粒度适中 | 1分 | 0.5分 | 故事大小是否适合一个迭代 |
| - 独立完整 | 1分 | 0.5分 | 故事是否独立且完整 |
| - 可测试性 | 1分 | 0.5分 | 是否有明确的验收标准 |
| **INVEST原则应用** | 3分 | 1.5分 | |
| - Independent独立性 | 0.5分 | 0.25分 | 故事之间是否相互独立 |
| - Negotiable可协商 | 0.5分 | 0.25分 | 故事是否留有协商空间 |
| - Valuable有价值 | 0.5分 | 0.25分 | 故事是否为用户创造价值 |
| - Estimable可估算 | 0.5分 | 0.25分 | 故事工作量是否可估算 |
| - Small小 | 0.5分 | 0.25分 | 故事是否足够小 |
| - Testable可测试 | 0.5分 | 0.25分 | 故事是否可测试 |
| **优先级排序** | 2分 | 1分 | |
| - MoSCoW方法应用 | 0.7分 | 0.35分 | 是否使用MoSCoW分类 |
| - 价值评估 | 0.7分 | 0.35分 | 是否基于业务价值排序 |
| - 依赖关系 | 0.6分 | 0.3分 | 是否考虑技术依赖关系 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某外卖APP"订餐功能"Epic

**任务说明**
- 使用AI将Epic拆解为用户故事
- 为每个用户故事编写验收标准
- 使用MoSCoW方法进行优先级排序

**提交成果**
- 用户故事列表（至少8个故事）
- INVEST原则检查表
- MoSCoW优先级矩阵

**评分要点**
- 故事拆解是否符合INVEST原则
- 验收标准是否明确、可测试
- 优先级排序是否合理
- 是否考虑技术依赖和业务价值

---

### B5：需求质量管理演练（8分，20分钟）

#### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **质量检查全面性** | 3分 | 1.5分 | |
| - 完整性检查 | 0.8分 | 0.4分 | 需求是否完整覆盖所有场景 |
| - 一致性检查 | 0.8分 | 0.4分 | 需求之间是否一致无矛盾 |
| - 可行性检查 | 0.7分 | 0.4分 | 需求是否技术可行 |
| - 可测试性检查 | 0.7分 | 0.3分 | 需求是否可测试验证 |
| **变更影响分析** | 3分 | 1.5分 | |
| - 影响范围识别 | 1分 | 0.5分 | 变更影响范围是否全面识别 |
| - 风险评估 | 1分 | 0.5分 | 变更风险是否准确评估 |
| - 应对措施 | 1分 | 0.5分 | 应对措施是否可行有效 |
| **工具应用创新** | 2分 | 1分 | |
| - AI工具使用 | 1分 | 0.5分 | AI工具是否有效辅助质量管理 |
| - 分析深度 | 1分 | 0.5分 | 质量分析是否深入全面 |
| **合计** | **8分** | **4分** | **保底比例：50%** |

#### 演练任务

**案例**：某PRD文档质量检查 + 需求变更影响分析

**任务说明**
- 使用AI对提供的PRD进行质量检查
- 针对一个需求变更场景，进行影响分析
- 提出质量改进建议和风险应对措施

**提交成果**
- 质量检查报告（完整性、一致性、可行性、可测试性）
- 变更影响分析矩阵
- 风险应对措施清单

**评分要点**
- 质量检查是否全面、准确
- 影响分析是否深入、完整
- 风险评估是否合理
- AI工具应用是否创新、有效

---

## 🎭 课堂表现评分详细标准

### 1. 开场展示（3分）

#### 评分维度

| 项目 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **团队介绍** | 1.5分 | 0.8分 | |
| - 团队名称 | 0.5分 | 0.3分 | 团队名称是否有创意 |
| - 成员介绍 | 0.5分 | 0.3分 | 成员介绍是否清晰 |
| - 角色分工 | 0.5分 | 0.2分 | 角色分工是否合理 |
| **AI工具箱展示** | 1.5分 | 0.7分 | |
| - 工具清单 | 0.5分 | 0.3分 | 是否列出所用AI工具 |
| - 使用方案 | 0.5分 | 0.2分 | 是否有工具使用计划 |
| - 预期效果 | 0.5分 | 0.2分 | 是否说明预期效果 |
| **合计** | **3分** | **1.5分** | **保底比例：50%** |

#### 操作指南

**时机**：第1天上午开场（09:15-09:30）

**要求**：
- 每组3-5分钟展示
- 介绍团队名称、成员、角色分工
- 展示准备的AI工具箱和使用方案

**评分要点**：
- 团队介绍是否清晰、有创意
- AI工具准备是否充分
- 团队精神面貌是否良好

---

### 2. 阶段总结（9分 = 3次×3分）

#### 评分维度

| 总结时机 | 分值 | 保底分 | 详细评分点 |
|----------|------|--------|-----------|
| **第1天下午总结** | 3分 | 1分 | |
| - 演练收获 | 1分 | 0.3分 | 是否总结上午演练的收获 |
| - 工具应用 | 0.5分 | 0.2分 | 是否分享AI工具应用心得 |
| - 团队协作 | 0.5分 | 0.2分 | 是否反思团队协作情况 |
| - 改进计划 | 1分 | 0.3分 | 是否提出改进计划 |
| **第2天上午总结** | 3分 | 1分 | |
| - 学习进展 | 1分 | 0.3分 | 是否总结第1天学习进展 |
| - 问题解决 | 0.5分 | 0.2分 | 是否分享遇到的问题和解决方法 |
| - 创新点 | 0.5分 | 0.2分 | 是否分享创新点 |
| - 下一步计划 | 1分 | 0.3分 | 是否明确第2天计划 |
| **第2天下午总结** | 3分 | 1分 | |
| - 整体回顾 | 1分 | 0.3分 | 是否全面回顾2天学习 |
| - 关键收获 | 0.5分 | 0.2分 | 是否总结关键收获 |
| - 实践心得 | 0.5分 | 0.2分 | 是否分享实践心得 |
| - 后续应用 | 1分 | 0.3分 | 是否计划后续应用 |
| **合计** | **9分** | **3分** | **保底比例：33%** |

#### 操作指南

**时机**：
- 第1天下午开场（14:00-14:10）
- 第2天上午开场（09:00-09:10）
- 第2天下午开场（14:00-14:10）

**要求**：
- 每组2-3分钟总结发言
- 围绕演练收获、团队协作、改进计划等维度
- 鼓励真实反思和创新分享

**评分要点**：
- 总结是否深入、有洞察
- 是否有具体的案例和数据
- 是否提出可行的改进计划
- 表达是否清晰、有感染力

---

### 3. 出勤准时（24分 = 8次×3分）

#### 评分标准

| 课次 | 时间节点 | 分值 | 评分规则 |
|------|----------|------|---------|
| **第1天上午** | 09:00开课 | 3分 | 全员到齐3分，缺1人2分，缺2人1分，缺3人及以上0分 |
| | 10:45休息后 | 3分 | 同上 |
| **第1天下午** | 14:00开课 | 3分 | 同上 |
| | 15:15休息后 | 3分 | 同上 |
| **第2天上午** | 09:00开课 | 3分 | 同上 |
| | 10:15休息后 | 3分 | 同上 |
| **第2天下午** | 14:00开课 | 3分 | 同上 |
| | 15:15休息后 | 3分 | 同上 |
| **合计** | - | **24分** | **保底12分（50%）** |

#### 评分规则

- **全员到齐**：3分/次
- **缺1人**：2分/次
- **缺2人**：1分/次
- **缺3人及以上**：0分/次
- **迟到判定**：迟到5分钟内算到齐，超过5分钟算缺席

#### 操作指南

**记录方式**：
- 助教在每个时间节点记录各组出勤情况
- 实时更新记分牌
- 特殊情况（如请假）需提前报备，酌情处理

**激励机制**：
- 全勤组额外表扬
- 出勤分可以拉开明显差距（最多24分）

---

### 4. 积极回答（10分，按次累计）

#### 评分标准

| 项目 | 单次分值 | 累计上限 | 评分要点 |
|------|----------|----------|---------|
| **主动回答问题** | 1分/次 | 10分 | 准确性、深度、启发性 |

#### 适用场景

- 讲师提问时主动举手回答
- 案例讨论时发表见解
- 难点问题时提供解决思路
- 帮助其他组解答疑问
- 课堂互动时积极参与

#### 评分原则

| 回答质量 | 得分 | 标准说明 |
|---------|------|---------|
| **优质回答** | 1分 | 准确、有深度、有启发性 |
| **一般回答** | 0.5分 | 基本正确但较浅显 |
| **重复回答** | 0分 | 与已有答案重复或无价值 |

#### 操作指南

**记录方式**：
1. 讲师或助教实时记录
2. 每次回答后立即判定分值
3. 实时更新记分牌
4. 达到10分上限后不再累计

**激励机制**：
- 鼓励组员轮流回答，避免个别人垄断
- 对深度回答给予特别表扬
- 公布各组积极回答排行榜

**注意事项**：
- 回答要有质量，避免为了得分而抢答
- 鼓励多角度思考，欢迎不同观点
- 回答错误不扣分，鼓励勇于尝试

---

### 5. 创新分享（5分，按次累计）

#### 评分标准

| 项目 | 单次分值 | 累计上限 | 评分要点 |
|------|----------|----------|---------|
| **创新实践分享** | 1分/次 | 5分 | 创新性、实用性、启发性 |

#### 适用场景

- 演练中发现的创新AI应用方法
- 独特的提示词设计技巧
- 创新的流程优化思路
- 实用的工具组合使用方案
- 特别的问题解决方法
- 新颖的需求分析视角
- 独创的文档模板或规范

#### 评分原则

| 创新质量 | 得分 | 标准说明 |
|---------|------|---------|
| **高价值创新** | 1分 | 新颖、实用、可推广 |
| **一般创新** | 0.5分 | 有新意但价值一般 |
| **非创新** | 0分 | 常规操作或已知方法 |

#### 分享方式

1. **演练展示时主动分享**：在演练汇报时专门介绍创新点
2. **阶段总结时专题介绍**：在阶段总结时分享创新实践
3. **课间休息时与讲师交流**：课间主动找讲师展示创新方法
4. **最终汇报时重点呈现**：在综合演练汇报时呈现创新应用

#### 操作指南

**记录方式**：
1. 讲师认定创新价值后现场记录
2. 每次分享后立即更新记分牌
3. 达到5分上限后不再累计
4. 建议建立"创新案例库"记录优秀创新

**激励机制**：
- 对高价值创新给予特别表扬
- 在课程结束时评选"最具创新奖"
- 鼓励各组相互学习、借鉴创新点

**创新示例**：
- ✅ 创新的提示词模板设计
- ✅ 多个AI工具的组合使用方案
- ✅ 独特的需求分析框架
- ✅ 新颖的UML图绘制技巧
- ✅ 高效的AI辅助质量检查方法
- ❌ 常规的AI工具使用（如普通的ChatGPT问答）
- ❌ 已知的标准操作流程
- ❌ 其他组已分享过的方法

---

## 🏅 综合演练评分（C1，20分）

### 评分维度

| 维度 | 分值 | 保底分 | 详细评分点 |
|------|------|--------|-----------|
| **需求开发基础能力** | 12分 | 7分 | |
| - 流程应用 | 3分 | 1.8分 | 需求开发流程应用是否规范 |
| - 文档质量 | 3分 | 1.8分 | PRD、用例等文档质量是否高 |
| - 建模规范 | 3分 | 1.7分 | UML建模是否符合标准 |
| - 工具使用 | 3分 | 1.7分 | AI工具使用是否熟练有效 |
| **创新与综合应用** | 5分 | 3分 | |
| - AI应用创新 | 2分 | 1.2分 | AI应用是否有创新点 |
| - 流程优化 | 2分 | 1.2分 | 是否提出流程优化建议 |
| - 综合思维 | 1分 | 0.6分 | 是否体现综合思维能力 |
| **汇报展示效果** | 3分 | 2分 | |
| - PPT质量 | 1分 | 0.7分 | PPT设计是否专业美观 |
| - 演讲表达 | 1分 | 0.7分 | 演讲是否清晰有感染力 |
| - 时间控制 | 1分 | 0.6分 | 时间控制是否得当 |
| **合计** | **20分** | **12分** | **保底比例：60%** |

### 实施流程

#### 1. 任务发布（第2天下午14:00）

**综合案例**：某智慧园区管理平台需求开发

**任务要求**：
1. 绘制系统Context Diagram
2. 梳理核心业务流程
3. 编写PRD文档（核心功能）
4. 绘制用例图并编写用例规约（至少2个核心用例）
5. 拆解用户故事并排优先级
6. 进行需求质量检查

#### 2. 独立完成（50分钟，14:10-15:00）

**操作要求**：
- 各组协作完成，可使用所有AI工具
- 可参考前面的演练成果
- 提交完整的需求文档包

**提交成果**：
- Context Diagram
- 业务流程图
- PRD文档
- 用例图和用例规约
- 用户故事列表和优先级矩阵
- 需求质量检查报告

#### 3. 汇报展示（15:00-16:45，每组10分钟+5分钟问答）

**汇报要求**：
- 准备PPT，时长10分钟
- 展示需求开发全流程成果
- 突出AI应用创新点
- 接受讲师和其他组的提问

**汇报结构建议**：
1. 项目背景和目标（1分钟）
2. 系统边界和范围（2分钟）
3. 核心流程和优化建议（2分钟）
4. 需求文档和用例建模（3分钟）
5. 用户故事和质量管理（1分钟）
6. AI应用创新点和总结（1分钟）

#### 4. 评分公布（16:30）

**评分流程**：
- 讲师现场打分
- 点评各组表现
- 公布综合演练得分
- 更新最终排行榜

---

## 💡 实施建议

### 1. 分差控制机制

**目标**：确保保底分约57分（46%），最大分差约67分（54%）

**控制策略**：

| 分值项 | 总分 | 保底分 | 最大分差 | 控制方法 |
|--------|------|--------|----------|----------|
| 演练成果 | 53分 | 27分 | 26分 | 每项50-60%保底，鼓励创新拉开差距 |
| 开场展示 | 3分 | 1.5分 | 1.5分 | 基础参与即有保底 |
| 阶段总结 | 9分 | 3分 | 6分 | 鼓励深度反思 |
| 出勤准时 | 24分 | 12分 | 12分 | 严格记录，全勤激励 |
| 积极回答 | 10分 | 0分 | 10分 | 按实际表现，鼓励主动参与 |
| 创新分享 | 5分 | 0分 | 5分 | 按实际创新，激励创新思维 |
| 综合演练 | 20分 | 12分 | 8分 | 60%保底，综合能力拉开差距 |

**平衡措施**：
- 演练成果有保底，确保基础公平
- 积极回答和创新分享无保底，激励主动参与
- 综合演练保底较高，避免最终一锤定音

### 2. 过程跟踪与反馈

**实时反馈**：
- 每个演练结束后立即公布得分
- 讲师现场点评，指出优点和改进点
- 大屏幕实时更新排行榜

**中期调整**：
- 第1天结束后，总结各组表现
- 识别落后组，给予鼓励和建议
- 调整第2天的教学节奏和重点

**最终总结**：
- 全面点评各组表现
- 分享优秀案例和创新点
- 颁发奖项，鼓励学员

### 3. 讲师评分技巧

**快速评分法**：
- 准备评分表，快速勾选
- 关注核心维度，避免过于细化
- 现场打分，避免事后补分

**公平性保障**：
- 同一标准评分，避免前后不一
- 多维度评分，避免主观偏见
- 记录评分理由，便于解释

**激励性设计**：
- 肯定优点，鼓励创新
- 指出改进点，提供建议
- 避免过于严苛，保持学习氛围

---

## 📚 附录：素材文档清单

### 演练案例素材

| 演练 | 案例名称 | 素材内容 |
|------|---------|---------|
| A1 | AI工具与提示词 | 提示词模板、MCP配置指南 |
| B0 | CRM系统 | 项目背景、业务简介 |
| B1 | 电商订单流程 | 当前流程描述、痛点清单 |
| B2 | 在线教育直播课堂 | 功能需求概述、用户角色 |
| B3 | 图书管理系统 | 系统功能清单、用户角色 |
| B4 | 外卖APP订餐功能 | Epic描述、业务场景 |
| B5 | PRD质量检查 | 待检查的PRD文档、变更场景 |
| C1 | 智慧园区管理平台 | 项目背景、业务需求概述 |

### 评分表模板

| 模板 | 用途 |
|------|------|
| 演练成果评分表 | A1、B0-B5评分 |
| 课堂表现记录表 | 出勤、回答、创新记录 |
| 综合演练评分表 | C1评分 |
| 总分汇总表 | 最终排名计算 |

### AI工具推荐清单

| 工具类别 | 推荐工具 | 用途 |
|---------|---------|------|
| 代码助手 | GitHub Copilot | 提示词辅助、代码生成 |
| 对话助手 | Claude、ChatGPT | 需求分析、文档生成 |
| 图表工具 | PlantUML + AI | UML图生成 |
| MCP服务 | Context7、Filesystem | 知识检索、文件操作 |

---

## 🎓 结语

本优化方案基于**124分评分体系**，详细说明了各演练的评分标准和操作指南。

**核心特色**：
- ✅ **详细的评分维度**：每个演练都有清晰的评分点和保底分
- ✅ **灵活的课堂表现分**：积极回答和创新分享按实际表现累计，激励主动参与
- ✅ **合理的分差控制**：保底约46%，最大分差约54%，确保公平和竞争
- ✅ **完整的操作指南**：从任务说明到评分要点，全面指导实施

**实施建议**：
- 讲师提前准备评分表和记分牌，确保实时更新
- 助教协助记录出勤、回答和创新，确保数据准确
- 鼓励学员主动参与、勇于创新，营造积极的学习氛围
- 及时反馈、持续激励，帮助各组不断进步

期待各组在训练营中收获满满，成长为AI时代的需求管理专家！🚀
